# Pyspark

_Pyspark  in Jupyter Notebook:_

Download:(Requirement)
* 1.Apache spark
* 2.Java JDK 8 version(only version works)
* 3.Anoconda
* 4.winutils-link :https://github.com/cdarlint/winutils/blob/master/hadoop-2.7.7/bin/winutils.exe
* 5.Python
* 6.FindSpark
* Set Environment variables & path
* Here :
* created 3 user variables:SPARK_HOME,HADOOP_HOME,JAVA_HOME,edited the path under system variable.

* ScreenShot:(Test run Success):
![image](https://user-images.githubusercontent.com/61881138/138630892-600cf33d-1b1a-451b-9de6-451868bb6922.png)


